defaults:
  - parser: pcfg

_target_: src.models.pretrain.PretrainPCFGModule
_recursive_: false

param_initializer: "xavier_uniform"
domain: "src"

parser:
  pt_states: 30
  nt_states: 30

optimizer:
  groups: ~
  args:
    _target_: torch.optim.AdamW
    lr: 5.0e-3
    betas: [0.9, 0.999]
    weight_decay: 1.0e-5
    eps: 1.0e-8

scheduler:
  interval: step
  frequency: 1
  monitor: val/ppl
  args:
    _target_: src.utils.scheduler.get_exponential_lr_scheduler
    gamma: 0.75**(1/5000)
