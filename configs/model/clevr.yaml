defaults:
  - encoder: yzhang_lstm
  - parser: pcfg
  - tree_encoder: treelstm
  - decoder: nodecomp
  - test_metric: bleu1234_and_exact

_target_: src.models.general_seq2seq.GeneralSeq2SeqModule
_recursive_: false

param_initializer: "xavier_uniform"

decoder_entropy_reg: 0.05
parser_entropy_reg: 0.05

embedding:
  _target_: torch.nn.Embedding
  embedding_dim: 200

encoder:
  hidden_size: 256
  dropout: 0.2

decoder:
  nt_states: 8
  pt_states: 8
  # rule_hard_constraint:
  #   _target_: src.models.constraint.fully_parameterized.FPSimpleHierarchy

optimizer:
  groups: ~
  args:
    _target_: torch.optim.AdamW
    lr: 5.0e-4
    betas: [0.75, 0.999]
    weight_decay: 1.0e-5
    eps: 1.0e-8

scheduler:
  ~
  # interval: step
  # frequency: 1
  # monitor: val/ppl
  # args:
  #   _target_: src.utils.scheduler.get_exponential_lr_scheduler
  #   gamma: 0.75**(1/10000)
